{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:51:11.719548Z",
     "start_time": "2019-08-19T07:51:11.401597Z"
    }
   },
   "outputs": [],
   "source": [
    "import xlearn as xl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:51:11.847886Z",
     "start_time": "2019-08-19T07:51:11.720873Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:39:14.388265Z",
     "start_time": "2019-08-19T08:39:14.381240Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from tqdm.autonotebook import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:51:12.667728Z",
     "start_time": "2019-08-19T07:51:12.642867Z"
    }
   },
   "outputs": [],
   "source": [
    "class FMFormat:\n",
    "    def __init__(self, vector_feat, onehot_feat, continous_feat):\n",
    "        self.feature_index = None  # 记录特征索引\n",
    "        self.vector_feat = vector_feat\n",
    "        self.onehot_feat = onehot_feat\n",
    "        self.continous_feat = continous_feat\n",
    "        \n",
    "    def fit(self, df):\n",
    "        self.feature_index = {}\n",
    "        last_idx = 0\n",
    "        for col in df.columns:\n",
    "            ## 如果是one-hot型特征\n",
    "            if col in self.onehot_feat:\n",
    "                print(\"cat\", col)\n",
    "                df[col] = df[col].astype(str)\n",
    "                ## 该变量对应多少种不同的值\n",
    "                vals = [v for v in np.unique(df[col].values) if str(v) != \"nan\"]\n",
    "                ## 获得对应的特征名\n",
    "                names = np.asarray(list(map(lambda x: col+\"_\"+x, vals)))\n",
    "                tmp = dict(zip(names, range(last_idx, last_idx+len(names))))\n",
    "                self.feature_index.update(tmp)\n",
    "                last_idx += len(names)\n",
    "            elif col in self.vector_feat:\n",
    "                ## 对于字符串类型的特征\n",
    "                vals = []\n",
    "                for data in df[col].astype(str).values:\n",
    "                    if data != \"nan\":\n",
    "                        ## 按照空格划分\n",
    "                        for word in data.strip().split():\n",
    "                            vals.append(word)\n",
    "                vals = np.unique(vals)\n",
    "                vals = filter(lambda x: x!=\"nan\", vals)\n",
    "                names = np.asarray(list(map(lambda x: col+\"_\"+x, vals)))\n",
    "                tmp = dict(zip(names, range(last_idx, last_idx+len(names))))\n",
    "                self.feature_index.update(tmp)\n",
    "                last_idx += len(names)\n",
    "            elif col in self.continous_feat:\n",
    "                ## 如果是数值型特征\n",
    "                print(\"con: \", col)\n",
    "                self.feature_index.update({col:last_idx})\n",
    "                last_idx += 1 \n",
    "        return self \n",
    "    \n",
    "    ## 对每一行进行转换\n",
    "    def transform_row_(self, row):\n",
    "        fm = []\n",
    "        \n",
    "        for col, val in row.loc[row != 0].to_dict().items():\n",
    "            if col in self.onehot_feat:\n",
    "                if str(val) != \"nan\":\n",
    "                    name = f\"{col}_{val}\"\n",
    "                    if name in self.feature_index:\n",
    "                        fm.append(\"{}:1\".format(self.feature_index[name]))\n",
    "            elif col in self.vector_feat:\n",
    "                if str(val) != \"nan\":\n",
    "                    for word in str(val).split():\n",
    "                        name = f\"{col}_{word}\"\n",
    "                        if name in self.feature_index:\n",
    "                            fm.append(\"{}:1\".format(self.feature_index[name]))\n",
    "            elif col in self.continous_feat:\n",
    "                if str(val) != \"nan\":\n",
    "                    fm.append(\"{}:{}\".format(self.feature_index[col], val))\n",
    "        return \" \".join(fm)\n",
    "    \n",
    "    def transform(self, df):\n",
    "        return pd.Series({idx:self.transform_row_(row) for idx, row in df.iterrows()})\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, df):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:29:43.027972Z",
     "start_time": "2019-08-19T08:29:42.998621Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_fm(train_df, test_df=None, vector_fe=[], onehot_fe=[], contin_fe=[], path=\"./\", label=None):\n",
    "    train_ = train_df.copy()\n",
    "    test_ = test_df.copy()\n",
    "    \n",
    "    if test_df is not None:\n",
    "        df_ = pd.concat([train_, test_], axis=0, sort=False, ignore_index=True)\n",
    "    else:\n",
    "        df_ = train_\n",
    "        \n",
    "    trans = FMFormat(vector_fe, onehot_fe, contin_fe)\n",
    "    user_fm = trans.fit_transform(df_)\n",
    "    \n",
    "    train_ = user_fm[:train_df.shape[0]]\n",
    "    if test_df is not None:\n",
    "        test_fm = user_fm[train_df.shape[0]:]\n",
    "    \n",
    "    if label:\n",
    "        Y = train_df[label].values\n",
    "    else:\n",
    "        raise ValueError(\"Please give the label\")\n",
    "        \n",
    "    train_fm = pd.DataFrame()\n",
    "    train_fm['Label'] = Y.astype(str)\n",
    "    train_fm['feature'] = train_\n",
    "    train_fm['all'] = train_fm[['Label', \"feature\"]].apply(lambda row: \" \".join(row),\n",
    "                                                          axis=1, raw=True)\n",
    "    train_fm.drop([\"Label\", \"feature\"], axis=1, inplace=True)\n",
    "    \n",
    "    ## 生成训练集和验证集\n",
    "    ### 生成训练集\n",
    "    train_string = \"\"\n",
    "    for i in range(int(train_fm.shape[0]*0.8)):\n",
    "        train_string += train_fm['all'].values[i]\n",
    "        train_string += \"\\n\"\n",
    "    train_string = train_string.strip()\n",
    "    with open(os.path.join(path, \"train_fm.txt\"), \"w\", encoding=\"utf8\") as f: \n",
    "        f.write(train_string)\n",
    "    \n",
    "    ### 生成验证集\n",
    "    valid_string = \"\"\n",
    "    for i in range(int(train_fm.shape[0]*0.8), train_fm.shape[0]):\n",
    "        valid_string += train_fm['all'].values[i]\n",
    "        valid_string += '\\n'\n",
    "    valid_string = valid_string.strip()\n",
    "    with open(os.path.join(path, \"valid_fm.txt\"), \"w\", encoding=\"utf8\") as f: \n",
    "        f.write(valid_string)\n",
    "    \n",
    "    if test_df is not None:\n",
    "        test_string = \"\"\n",
    "        for i in range(test_fm.shape[0]):\n",
    "            test_string += test_fm.values[i]\n",
    "            test_string += \"\\n\"\n",
    "        test_string = test_string.strip()\n",
    "        with open(os.path.join(path, \"test_fm.txt\"), \"w\", encoding=\"utf8\") as f: \n",
    "            f.write(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:24:26.620703Z",
     "start_time": "2019-08-19T08:24:26.584475Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/criteo/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:24:26.756735Z",
     "start_time": "2019-08-19T08:24:26.748496Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../data/criteo/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:24:27.943524Z",
     "start_time": "2019-08-19T08:24:27.939619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9',\n",
       "       'I10', 'I11', 'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7',\n",
       "       'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17',\n",
       "       'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:03:57.748841Z",
     "start_time": "2019-08-19T08:03:57.746554Z"
    }
   },
   "outputs": [],
   "source": [
    "con = [f for f in train.columns if f.startswith(\"I\") and f!=\"Id\"]\n",
    "cat = [f for f in train.columns if f.startswith(\"C\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 只使用特征型变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:51:14.696970Z",
     "start_time": "2019-08-19T07:51:14.005456Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat C1\n",
      "cat C2\n",
      "cat C3\n",
      "cat C4\n",
      "cat C5\n",
      "cat C6\n",
      "cat C7\n",
      "cat C8\n",
      "cat C9\n",
      "cat C10\n",
      "cat C11\n",
      "cat C12\n",
      "cat C13\n",
      "cat C14\n",
      "cat C15\n",
      "cat C16\n",
      "cat C17\n",
      "cat C18\n",
      "cat C19\n",
      "cat C20\n",
      "cat C21\n",
      "cat C22\n",
      "cat C23\n",
      "cat C24\n",
      "cat C25\n",
      "cat C26\n"
     ]
    }
   ],
   "source": [
    "convert_to_fm(train_df=train, test_df=test, onehot_fe=cat, label=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:51:14.979259Z",
     "start_time": "2019-08-19T07:51:14.977455Z"
    }
   },
   "outputs": [],
   "source": [
    "fm_model = xl.create_fm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:51:15.571003Z",
     "start_time": "2019-08-19T07:51:15.568922Z"
    }
   },
   "outputs": [],
   "source": [
    "fm_model.setTrain(\"./train_fm.txt\")\n",
    "fm_model.setValidate(\"./valid_fm.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:51:16.468505Z",
     "start_time": "2019-08-19T07:51:16.466604Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {\"task\": \"binary\", \"lr\": 0.1, \"lambda\": 0.002, \"metric\": \"acc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:51:17.970790Z",
     "start_time": "2019-08-19T07:51:17.962518Z"
    }
   },
   "outputs": [],
   "source": [
    "fm_model.fit(param, \"./model.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:51:28.182854Z",
     "start_time": "2019-08-19T07:51:28.180598Z"
    }
   },
   "outputs": [],
   "source": [
    "fm_model.setTest(\"./test_fm.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:51:28.859457Z",
     "start_time": "2019-08-19T07:51:28.855538Z"
    }
   },
   "outputs": [],
   "source": [
    "fm_model.setSigmoid()\n",
    "\n",
    "fm_model.predict(\"./model.out\", './output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=red>**验证集准确率0.768750**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对连续型特征进行归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用正态归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:13:47.762507Z",
     "start_time": "2019-08-19T08:13:47.758896Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(train_df, test_df=None, contin_fe=[]):\n",
    "    '''\n",
    "    只需要处理连续型特征即可\n",
    "    '''\n",
    "    if test_df is not None:\n",
    "        df_ = pd.concat([train_df, test_df], axis=0, sort=False, ignore_index=True)\n",
    "    else:\n",
    "        df_ = train_df\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    df_[contin_fe] = ss.fit_transform(df_[contin_fe])\n",
    "    \n",
    "    train_df = df_[:train_df.shape[0]]\n",
    "    if test_df is not None:\n",
    "        test_df = df_[train_df.shape[0]:]\n",
    "        return train_df, test_df\n",
    "    return train_df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:13:48.442886Z",
     "start_time": "2019-08-19T08:13:48.430863Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chen/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/chen/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = preprocess(train, test, contin_fe=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:13:50.343960Z",
     "start_time": "2019-08-19T08:13:49.591891Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "con:  I1\n",
      "con:  I2\n",
      "con:  I3\n",
      "con:  I4\n",
      "con:  I5\n",
      "con:  I6\n",
      "con:  I7\n",
      "con:  I8\n",
      "con:  I9\n",
      "con:  I10\n",
      "con:  I11\n",
      "con:  I12\n",
      "con:  I13\n",
      "cat C1\n",
      "cat C2\n",
      "cat C3\n",
      "cat C4\n",
      "cat C5\n",
      "cat C6\n",
      "cat C7\n",
      "cat C8\n",
      "cat C9\n",
      "cat C10\n",
      "cat C11\n",
      "cat C12\n",
      "cat C13\n",
      "cat C14\n",
      "cat C15\n",
      "cat C16\n",
      "cat C17\n",
      "cat C18\n",
      "cat C19\n",
      "cat C20\n",
      "cat C21\n",
      "cat C22\n",
      "cat C23\n",
      "cat C24\n",
      "cat C25\n",
      "cat C26\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-ed2ef7c89239>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvert_to_fm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontin_fe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monehot_fe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-aca6a5c287cd>\u001b[0m in \u001b[0;36mconvert_to_fm\u001b[0;34m(train_df, test_df, vector_fe, onehot_fe, contin_fe, path, label)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please give the label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;36m3\u001b[0m  \u001b[0mmonkey\u001b[0m        \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \"\"\"\n\u001b[0;32m--> 809\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4375\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4376\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Label'"
     ]
    }
   ],
   "source": [
    "convert_to_fm(train_df=train_df, test_df=test_df, contin_fe=con, onehot_fe=cat, label=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:56:01.149374Z",
     "start_time": "2019-08-19T07:56:01.147167Z"
    }
   },
   "outputs": [],
   "source": [
    "fm_model = xl.create_fm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:56:29.137243Z",
     "start_time": "2019-08-19T07:56:29.134109Z"
    }
   },
   "outputs": [],
   "source": [
    "fm_model.setTrain(\"./train_fm.txt\")\n",
    "fm_model.setValidate(\"./valid_fm.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:56:39.550755Z",
     "start_time": "2019-08-19T07:56:39.548605Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {\"task\": \"binary\", \"lr\": 0.1, \"lambda\": 0.002, \"metric\": \"acc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T07:57:02.825604Z",
     "start_time": "2019-08-19T07:57:02.807706Z"
    }
   },
   "outputs": [],
   "source": [
    "fm_model.fit(param, './model.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=4>**验证集准确率0.771875**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用最大最小值归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:11:41.712964Z",
     "start_time": "2019-08-19T08:11:41.709156Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(train_df, test_df=None, contin_fe=[]):\n",
    "    '''\n",
    "    只需要处理连续型特征即可\n",
    "    '''\n",
    "    if test_df is not None:\n",
    "        df_ = pd.concat([train_df, test_df], axis=0, sort=False, ignore_index=True)\n",
    "    else:\n",
    "        df_ = train_df\n",
    "    \n",
    "    mm = MinMaxScaler()\n",
    "    df_[contin_fe] = mm.fit_transform(df_[contin_fe])\n",
    "    \n",
    "    train_df = df_[:train_df.shape[0]]\n",
    "    if test_df is not None:\n",
    "        test_df = df_[train_df.shape[0]:]\n",
    "        return train_df, test_df\n",
    "    return train_df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:11:42.066734Z",
     "start_time": "2019-08-19T08:11:42.047675Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chen/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = preprocess(train, test, contin_fe=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:11:50.012702Z",
     "start_time": "2019-08-19T08:11:50.002037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9',\n",
       "       'I10', 'I11', 'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7',\n",
       "       'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17',\n",
       "       'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:04:39.562273Z",
     "start_time": "2019-08-19T08:04:38.813594Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "con:  I1\n",
      "con:  I2\n",
      "con:  I3\n",
      "con:  I4\n",
      "con:  I5\n",
      "con:  I6\n",
      "con:  I7\n",
      "con:  I8\n",
      "con:  I9\n",
      "con:  I10\n",
      "con:  I11\n",
      "con:  I12\n",
      "con:  I13\n",
      "cat C1\n",
      "cat C2\n",
      "cat C3\n",
      "cat C4\n",
      "cat C5\n",
      "cat C6\n",
      "cat C7\n",
      "cat C8\n",
      "cat C9\n",
      "cat C10\n",
      "cat C11\n",
      "cat C12\n",
      "cat C13\n",
      "cat C14\n",
      "cat C15\n",
      "cat C16\n",
      "cat C17\n",
      "cat C18\n",
      "cat C19\n",
      "cat C20\n",
      "cat C21\n",
      "cat C22\n",
      "cat C23\n",
      "cat C24\n",
      "cat C25\n",
      "cat C26\n"
     ]
    }
   ],
   "source": [
    "convert_to_fm(train_df=train_df, test_df=test_df, \n",
    "              contin_fe=con, onehot_fe=cat, label=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:05:09.069917Z",
     "start_time": "2019-08-19T08:05:09.052627Z"
    }
   },
   "outputs": [],
   "source": [
    "fm_model = xl.create_fm()\n",
    "\n",
    "fm_model.setTrain(\"./train_fm.txt\")\n",
    "fm_model.setValidate(\"./valid_fm.txt\")\n",
    "\n",
    "param = {\"task\": \"binary\", \"lr\": 0.1, \"lambda\": 0.002, \"metric\": \"acc\"}\n",
    "\n",
    "fm_model.fit(param, './model.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=red>**验证集准确率0.76875**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对连续型特征进行分箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:30:02.042046Z",
     "start_time": "2019-08-19T08:30:02.016899Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对跨度比较大的连续值进行分箱\n",
    "## 分箱节点为：0, 25, 50, 75, 95, 100\n",
    "def cut_bins(train, test=None, contin_fe=[]):\n",
    "    if test is not None:\n",
    "        df_ = pd.concat([train, test], axis=0, sort=False, ignore_index=True)\n",
    "    else:\n",
    "        df_ = train\n",
    "    ## 计算几个分位点\n",
    "    ## 去除所有nan值\n",
    "    for col in contin_fe:\n",
    "        ### 去除nan值\n",
    "        vals = df_[np.isnan(df_[col]).astype('int8') == 0][col].values\n",
    "        Q0 = np.min(vals)\n",
    "        Q1 = np.percentile(vals, 25)\n",
    "        Q2 = np.percentile(vals, 50)\n",
    "        Q3 = np.percentile(vals, 75)\n",
    "        Q4 = np.percentile(vals, 95)\n",
    "        Q5 = np.max(vals)\n",
    "        bins = [Q0, Q1, Q2, Q3, Q4, Q5]\n",
    "        bins = sorted(set(bins))\n",
    "        labels = list(map(str, list(range(len(bins)-1))))\n",
    "        df_[f\"C_{col}\"] = pd.cut(df_[col], bins=bins, labels=labels)\n",
    "    \n",
    "    train_ = df_[:train.shape[0]]\n",
    "    if test is not None:\n",
    "        test_ = df_[train.shape[0]:]\n",
    "        return train_, test_\n",
    "    return train_, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:30:02.234587Z",
     "start_time": "2019-08-19T08:30:02.166064Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = cut_bins(train, test, contin_fe=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:30:03.072012Z",
     "start_time": "2019-08-19T08:30:03.069095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9',\n",
       "       'I10', 'I11', 'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7',\n",
       "       'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17',\n",
       "       'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C_I1',\n",
       "       'C_I2', 'C_I3', 'C_I4', 'C_I5', 'C_I6', 'C_I7', 'C_I8', 'C_I9', 'C_I10',\n",
       "       'C_I11', 'C_I12', 'C_I13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:30:03.734696Z",
     "start_time": "2019-08-19T08:30:03.732702Z"
    }
   },
   "outputs": [],
   "source": [
    "new_cat = [f for f in train_df.columns if f.startswith(\"C\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:30:05.267238Z",
     "start_time": "2019-08-19T08:30:04.510229Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat C1\n",
      "cat C2\n",
      "cat C3\n",
      "cat C4\n",
      "cat C5\n",
      "cat C6\n",
      "cat C7\n",
      "cat C8\n",
      "cat C9\n",
      "cat C10\n",
      "cat C11\n",
      "cat C12\n",
      "cat C13\n",
      "cat C14\n",
      "cat C15\n",
      "cat C16\n",
      "cat C17\n",
      "cat C18\n",
      "cat C19\n",
      "cat C20\n",
      "cat C21\n",
      "cat C22\n",
      "cat C23\n",
      "cat C24\n",
      "cat C25\n",
      "cat C26\n",
      "cat C_I1\n",
      "cat C_I2\n",
      "cat C_I3\n",
      "cat C_I4\n",
      "cat C_I5\n",
      "cat C_I6\n",
      "cat C_I7\n",
      "cat C_I8\n",
      "cat C_I9\n",
      "cat C_I10\n",
      "cat C_I11\n",
      "cat C_I12\n",
      "cat C_I13\n"
     ]
    }
   ],
   "source": [
    "convert_to_fm(train_df=train_df, test_df=test_df,\n",
    "             onehot_fe=new_cat, label=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:30:19.534479Z",
     "start_time": "2019-08-19T08:30:19.518400Z"
    }
   },
   "outputs": [],
   "source": [
    "fm_model = xl.create_fm()\n",
    "\n",
    "fm_model.setTrain(\"./train_fm.txt\")\n",
    "fm_model.setValidate(\"./valid_fm.txt\")\n",
    "\n",
    "param = {\"task\": \"binary\", \"lr\": 0.1, \"lambda\": 0.002, \"metric\": \"acc\"}\n",
    "\n",
    "fm_model.fit(param, './model.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=red>**验证集准确率0.771875**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用FFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:32:32.161468Z",
     "start_time": "2019-08-19T08:32:32.146106Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义将数据转换为xlearn格式的数据\n",
    "class FFMFormat:\n",
    "    def __init__(self, vector_feat, one_hot_feat, continus_feat):\n",
    "        '''\n",
    "        vector_feat: 表示多个有意义的字符组成的特征，可以理解为向量型特征，缺失值用\"-1\"填充 \n",
    "        one_hot_feat: 表示可以使用One-hot编码的特征，缺失值使用-1填充 \n",
    "        continus_feat: 表示连续型特征，经过归一化处理的 \n",
    "        '''\n",
    "        self.field_index_ = None  # 记录场索引信息\n",
    "        self.feature_index_ = None # 记录特征索引信息\n",
    "        self.vector_feat = vector_feat\n",
    "        self.one_hot_feat = one_hot_feat\n",
    "        self.continus_feat = continus_feat\n",
    "        \n",
    "    def fit(self, df):\n",
    "        ## 每一列对应一个场\n",
    "        self.field_index_ = {col: i for i, col in enumerate(df.columns)}\n",
    "        self.feature_index_ = {}\n",
    "        last_idx = 0 \n",
    "        for col in tqdm(df.columns):\n",
    "            ## 如果对应列是one-hot型特征\n",
    "            if col in self.one_hot_feat:\n",
    "                print(\"cat: \", col)\n",
    "                df[col] = df[col].astype(str)\n",
    "                ## 求出该变量中共有多少种不同的值\n",
    "                vals = [v for v in np.unique(df[col].values) if str(v) != \"nan\"]\n",
    "                ## 获得对应的one-hot只有的特征名\n",
    "                names = np.asarray(list(map(lambda x: col+\"_\"+x, vals)))\n",
    "                tmp = dict(zip(names, range(last_idx, last_idx+len(names))))\n",
    "                self.feature_index_[col] = tmp\n",
    "                last_idx += len(names)\n",
    "            elif col in self.vector_feat:\n",
    "                ## 这是字符串型特征\n",
    "                vals = []\n",
    "                for data in df[col].apply(str):\n",
    "                    if data != \"nan\":\n",
    "                        ## 按照空格进行分割\n",
    "                        for word in data.strip().split():\n",
    "                            vals.append(word)\n",
    "                vals = np.unique(vals)\n",
    "                vals = filter(lambda x: x!=\"nan\", vals)\n",
    "                names = np.asarray(list(map(lambda x: col+\"_\"+x, vals)))\n",
    "                tmp = dict(zip(names, range(last_idx, last_idx+len(names))))\n",
    "                self.feature_index_[col] = tmp\n",
    "                last_idx += len(names)\n",
    "            elif col in self.continus_feat:\n",
    "                ## 最后如果是数值型特征\n",
    "                print(\"con: \", col)\n",
    "                self.feature_index_[col] = last_idx\n",
    "                last_idx += 1 \n",
    "        return self \n",
    "    \n",
    "    # 对每一行进行转换\n",
    "    def transform_row_(self, row):\n",
    "        ffm = []\n",
    "        \n",
    "        for col, val in row.loc[row != 0].to_dict().items():\n",
    "            if col in self.one_hot_feat:\n",
    "                name = f\"{col}_{val}\"\n",
    "                if name in self.feature_index_[col]:\n",
    "                    ffm.append(\"{}:{}:1\".format(self.field_index_[col], self.feature_index_[col][name]))\n",
    "            elif col in self.vector_feat:\n",
    "                for word in str(val).split():\n",
    "                    name = f\"{col}_{word}\"\n",
    "                    if name in self.feature_index_[col]:\n",
    "                        ffm.append(\"{}:{}:1\".format(self.field_index_[col], self.feature_index_[col][name]))\n",
    "            elif col in self.continus_feat:\n",
    "                if str(val) != \"nan\": \n",
    "                    ffm.append(\"{}:{}:{}\".format(self.field_index_[col], self.feature_index_[col], val))\n",
    "        return \" \".join(ffm)\n",
    "    \n",
    "    def transform(self, df):\n",
    "        return pd.Series({idx: self.transform_row_(row) for idx, row in tqdm(df.iterrows())})\n",
    "    \n",
    "    def fit_transform(self, df):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:35:12.567242Z",
     "start_time": "2019-08-19T08:35:12.557646Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_ffm(train_df, test_df=None, vector_fe=[], onehot_fe=[], contin_fe=[], path=\"./\", label=None):\n",
    "    \n",
    "    train_ = train_df.copy()\n",
    "    test_ = test_df.copy()\n",
    "    \n",
    "    if test_df is not None:\n",
    "        df_ = pd.concat([train_, test_], axis=0, sort=False, ignore_index=True)\n",
    "    else:\n",
    "        df_ = train_\n",
    "    \n",
    "    trans = FFMFormat(vector_fe, onehot_fe, contin_fe)\n",
    "    user_ffm = trans.fit_transform(df_)\n",
    "    \n",
    "    train_ = user_ffm[:train_df.shape[0]]\n",
    "    if test_df is not None:\n",
    "        test_ffm = user_ffm[train_df.shape[0]:]\n",
    "    \n",
    "    if label:\n",
    "        Y = train_df[label].values\n",
    "    else:\n",
    "        raise ValueError(\"Please give the label\")\n",
    "    \n",
    "    train_ffm = pd.DataFrame()\n",
    "    train_ffm[\"Label\"] = Y.astype(str) \n",
    "    train_ffm[\"feature\"] = train_\n",
    "    train_ffm['all'] = train_ffm[['Label', \"feature\"]].apply(lambda row: \" \".join(row), axis=1, raw=True)\n",
    "    train_ffm.drop([\"Label\", \"feature\"], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    ## 生成训练集和验证集\n",
    "    ### 生成训练集\n",
    "    train_string = \"\"\n",
    "    for i in range(int(train_ffm.shape[0]*0.8)):\n",
    "        train_string += train_ffm['all'].values[i]\n",
    "        train_string += \"\\n\"\n",
    "    train_string = train_string.strip()\n",
    "    with open(os.path.join(path, \"train_ffm.txt\"), \"w\", encoding=\"utf8\") as f: \n",
    "        f.write(train_string)\n",
    "    \n",
    "    ### 生成验证集\n",
    "    valid_string = \"\"\n",
    "    for i in range(int(train_ffm.shape[0]*0.8), train_ffm.shape[0]):\n",
    "        valid_string += train_ffm['all'].values[i]\n",
    "        valid_string += '\\n'\n",
    "    valid_string = valid_string.strip()\n",
    "    with open(os.path.join(path, \"valid_ffm.txt\"), \"w\", encoding=\"utf8\") as f: \n",
    "        f.write(valid_string)\n",
    "    \n",
    "    if test_df is not None:\n",
    "        test_string = \"\"\n",
    "        for i in range(test_ffm.shape[0]):\n",
    "            test_string += test_ffm.values[i]\n",
    "            test_string += \"\\n\"\n",
    "        test_string = test_string.strip()\n",
    "        with open(os.path.join(path, \"test_ffm.txt\"), \"w\", encoding=\"utf8\") as f: \n",
    "            f.write(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用归一化之后的连续特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:35:56.578909Z",
     "start_time": "2019-08-19T08:35:56.558433Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(train_df, test_df=None, contin_fe=[]):\n",
    "    '''\n",
    "    只需要处理连续型特征即可\n",
    "    '''\n",
    "    if test_df is not None:\n",
    "        df_ = pd.concat([train_df, test_df], axis=0, sort=False, ignore_index=True)\n",
    "    else:\n",
    "        df_ = train_df\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    df_[contin_fe] = ss.fit_transform(df_[contin_fe])\n",
    "    \n",
    "    train_df = df_[:train_df.shape[0]]\n",
    "    if test_df is not None:\n",
    "        test_df = df_[train_df.shape[0]:]\n",
    "        return train_df, test_df\n",
    "    return train_df, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:37:49.814743Z",
     "start_time": "2019-08-19T08:37:49.778455Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chen/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/chen/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = preprocess(train, test, contin_fe=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:39:24.803545Z",
     "start_time": "2019-08-19T08:39:23.996042Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e0ca4e56e3475c98ea17f626f0a535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "con:  I1\n",
      "con:  I2\n",
      "con:  I3\n",
      "con:  I4\n",
      "con:  I5\n",
      "con:  I6\n",
      "con:  I7\n",
      "con:  I8\n",
      "con:  I9\n",
      "con:  I10\n",
      "con:  I11\n",
      "con:  I12\n",
      "con:  I13\n",
      "cat:  C1\n",
      "cat:  C2\n",
      "cat:  C3\n",
      "cat:  C4\n",
      "cat:  C5\n",
      "cat:  C6\n",
      "cat:  C7\n",
      "cat:  C8\n",
      "cat:  C9\n",
      "cat:  C10\n",
      "cat:  C11\n",
      "cat:  C12\n",
      "cat:  C13\n",
      "cat:  C14\n",
      "cat:  C15\n",
      "cat:  C16\n",
      "cat:  C17\n",
      "cat:  C18\n",
      "cat:  C19\n",
      "cat:  C20\n",
      "cat:  C21\n",
      "cat:  C22\n",
      "cat:  C23\n",
      "cat:  C24\n",
      "cat:  C25\n",
      "cat:  C26\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87da9c5c1eee45f5b0c158768200497c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_to_ffm(train_df=train_df, test_df=test_df, contin_fe=con, onehot_fe=cat,\n",
    "              label=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:40:09.092109Z",
     "start_time": "2019-08-19T08:40:08.995285Z"
    }
   },
   "outputs": [],
   "source": [
    "ffm_model = xl.create_ffm()\n",
    "\n",
    "ffm_model.setTrain(\"./train_ffm.txt\")\n",
    "ffm_model.setValidate(\"./valid_ffm.txt\")\n",
    "\n",
    "param = {\"task\": \"binary\", \"lr\": 0.1, \"lambda\": 0.002, \"metric\": \"acc\"}\n",
    "\n",
    "ffm_model.fit(param, './model.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=red>**验证集准确率0.7750**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对连续型特征进行分箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:41:44.786251Z",
     "start_time": "2019-08-19T08:41:44.733584Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = cut_bins(train, test, contin_fe=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:42:17.274088Z",
     "start_time": "2019-08-19T08:42:17.272091Z"
    }
   },
   "outputs": [],
   "source": [
    "new_cat = [f for f in train_df if f.startswith(\"C\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:42:45.014576Z",
     "start_time": "2019-08-19T08:42:44.203936Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99449e57de1d441b9d580c3ece4cbdb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat:  C1\n",
      "cat:  C2\n",
      "cat:  C3\n",
      "cat:  C4\n",
      "cat:  C5\n",
      "cat:  C6\n",
      "cat:  C7\n",
      "cat:  C8\n",
      "cat:  C9\n",
      "cat:  C10\n",
      "cat:  C11\n",
      "cat:  C12\n",
      "cat:  C13\n",
      "cat:  C14\n",
      "cat:  C15\n",
      "cat:  C16\n",
      "cat:  C17\n",
      "cat:  C18\n",
      "cat:  C19\n",
      "cat:  C20\n",
      "cat:  C21\n",
      "cat:  C22\n",
      "cat:  C23\n",
      "cat:  C24\n",
      "cat:  C25\n",
      "cat:  C26\n",
      "cat:  C_I1\n",
      "cat:  C_I2\n",
      "cat:  C_I3\n",
      "cat:  C_I4\n",
      "cat:  C_I5\n",
      "cat:  C_I6\n",
      "cat:  C_I7\n",
      "cat:  C_I8\n",
      "cat:  C_I9\n",
      "cat:  C_I10\n",
      "cat:  C_I11\n",
      "cat:  C_I12\n",
      "cat:  C_I13\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fb3123e0994079a1b0fcbafdd1e6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_to_ffm(train_df, test_df, onehot_fe=new_cat, label=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T08:43:00.127706Z",
     "start_time": "2019-08-19T08:43:00.005688Z"
    }
   },
   "outputs": [],
   "source": [
    "ffm_model = xl.create_ffm()\n",
    "\n",
    "ffm_model.setTrain(\"./train_ffm.txt\")\n",
    "ffm_model.setValidate(\"./valid_ffm.txt\")\n",
    "\n",
    "param = {\"task\": \"binary\", \"lr\": 0.1, \"lambda\": 0.002, \"metric\": \"acc\"}\n",
    "\n",
    "ffm_model.fit(param, './model.out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=4>**验证集准确率0.771875**</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
